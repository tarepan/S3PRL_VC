{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oWm0zXecPh6"
      },
      "source": [
        "# s3prlvc\n",
        "[![Generic badge](https://img.shields.io/badge/GitHub-s3prlvc-9cf.svg)][github]\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)][notebook]\n",
        "\n",
        "Author: [tarepan]\n",
        "\n",
        "[github]:https://github.com/tarepan/S3PRL_VC\n",
        "[notebook]:https://colab.research.google.com/github/tarepan/S3PRL_VC/blob/main/s3prlvc.ipynb\n",
        "[tarepan]:https://github.com/tarepan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFQivUIyZyYi"
      },
      "source": [
        "## Colab Check\n",
        "Check\n",
        "- Google Colaboratory runnning time\n",
        "- GPU type\n",
        "- Python version\n",
        "- CUDA version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cwyMoXOZ7e1",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "!cat /proc/uptime | awk '{print $1 /60 /60 /24 \"days (\" $1 \"sec)\"}'\n",
        "!head -n 1 /proc/driver/nvidia/gpus/**/information\n",
        "!python --version\n",
        "!pip show torch | sed '2!d'\n",
        "!/usr/local/cuda/bin/nvcc --version | sed '4!d'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K125Ein7VCwM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJCLLQ_8cPiM"
      },
      "source": [
        "Install the package from `tarepan/S3PRL_VC` public repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZ9fU-17Sdxb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# GoogleDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Dedicated dependencies install\n",
        "# !pip install \"torch==1.10.0\" -q      # Based on your PyTorch environment\n",
        "# !pip install \"torchaudio==0.10.0\" -q # Based on your PyTorch environment\n",
        "\n",
        "# Prerequisites\n",
        "!apt-get install sox\n",
        "\n",
        "# repository install\n",
        "!pip uninstall s3prlvc -y -q\n",
        "!pip install git+https://github.com/tarepan/S3PRL_VC -q\n",
        "\n",
        "# Pretrained models\n",
        "## Unit2Mel: vq-wav2vec (If you omit this 2 lines, s3prl automatically download the model)\n",
        "!mkdir -p /root/.cache/torch/hub\n",
        "!cp -r /content/gdrive/MyDrive/ML_data/s3prl_cache /root/.cache/torch/hub\n",
        "## Mel2Wave: HiFi-GAN (prerequisite: download the model from `https://drive.google.com/file/d/12w1LpF6HjsJBmOUUkS6LV1d7AX18SA7u`)\n",
        "!mkdir -p /root/.cache/parallel_wavegan/12w1LpF6HjsJBmOUUkS6LV1d7AX18SA7u\n",
        "!cp -r /content/gdrive/MyDrive/ML_data/pretrained/HiFiGAN/hifigan_vctk/* /root/.cache/parallel_wavegan/12w1LpF6HjsJBmOUUkS6LV1d7AX18SA7u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptA8A-dhEgqZ"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKIasW5cTqhl",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# Launch TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir gdrive/MyDrive/ML_results/s3prlvc\n",
        "\n",
        "# Train\n",
        "!python -m s3prlvc.main_train \\\n",
        "    train.ckpt_log.dir_root=gdrive/MyDrive/ML_results/s3prlvc \\\n",
        "    train.ckpt_log.name_exp=default \\\n",
        "    train.ckpt_log.name_version=version_default \\\n",
        "    data.adress_data_root=gdrive/MyDrive/ML_data \\\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# .wav I/O\n",
        "!python -m s3prlvc.main_inference \\\n",
        "    model_ckpt_path=\"gdrive/MyDrive/ML_results/s3prlvc/default/version_-1/checkpoints/last.ckpt\" \\\n",
        "    i_wav_path=\"./hello.wav\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# # data I/O\n",
        "# from IPython.display import Audio, display\n",
        "\n",
        "# from torch import inference_mode\n",
        "# import torchaudio\n",
        "# import soundfile as sf\n",
        "\n",
        "# from rnnms.model import RNNMS\n",
        "\n",
        "\n",
        "# torchaudio.set_audio_backend(\"sox_io\")\n",
        "# CKPT_PATH = \"gdrive/MyDrive/ML_results/rnnms/default/version_-1/checkpoints/last.ckpt\"\n",
        "# model = RNNMS.load_from_checkpoint(checkpoint_path=CKPT_PATH)\n",
        "\n",
        "# wave, orig_sr = model.sample_wave()\n",
        "# # import librosa\n",
        "# # I_WAV_PATH = \"\"\n",
        "# # wave, orig_sr = librosa.load(I_WAV_PATH)\n",
        "\n",
        "# with inference_mode():\n",
        "#     mel = model.wav2mel(wave, orig_sr)\n",
        "#     o_wave, o_sr = model.predict(mel)\n",
        "# o_wave = o_wave[0].to('cpu').detach().numpy()\n",
        "\n",
        "# display(Audio(o_wave, rate=o_sr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0O2DDaFlcPiX",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# # Usage stat\n",
        "# ## GPU\n",
        "# !nvidia-smi -l 3\n",
        "# ## CPU\n",
        "# !vmstat 5\n",
        "# !top"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "s3prlvc.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
